在当今信息爆炸的时代，如何高效地从海量数据中获取有用信息成为一项重大挑战。为了解决这一问题，`检索增强生成（RAG，Retrieval-Augmented Generation）`应运而生。

RAG 是一种结合了信息检索和生成模型的技术，它能够从知识库中检索相关信息，并将其整合到生成的回答中，从而提供更加准确和丰富的回答。

**RAG 技术由两个主要部分组成：检索（Retrieval）和生成（Generation）**。

首先，系统会将用户的查询转换为向量表示，并在知识库中寻找最相似的文档片段。然后，系统将这些检索到的信息整合到生成模型中，最终生成一个包含相关信息的回答。这种方法既能利用知识库中的海量信息，又能通过生成模型提供流畅、自然的回答。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7ccfeb41c1ba4770afe4df790fe12d3c~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=1694&h=429&s=153781&e=png&b=fefefe)

目前大热的 AI 大语言生成模型，如 GPT-4，虽然在许多情况下表现出色，但在处理一些复杂或领域特定的问题时，可能会由于缺乏相关背景知识而产生错误或不完整的回答。RAG 技术通过结合检索和生成两种方法，显著提升了回答的准确性和信息量。它在客服、教育、医疗等领域都有广泛的应用前景。

## Coze 平台与 RAG

Coze 作为一个新手友好、功能丰富的 AI Agent 编排平台，也提供了其知识库功能，完美契合 RAG 技术。Coze 的知识库功能允许用户上传和管理各种格式类型的数据，比如文本、表格等。这些数据经过组织和索引后，可以高效地被检索和应用，从而为 RAG 系统提供了丰富的素材。

在 Coze 平台上，知识库通过以下几个步骤实现高效管理：

1. **数据上传与预处理**：用户可以上传本地文件、在线网页、Notion 文档等多种数据源，Coze 平台会自动对这些数据进行切分和清洗，确保数据质量。
2. **向量索引**：Coze 采用向量索引技术，将数据片段进行语义向量化，使相似内容在向量空间中靠近，从而提高检索效率。
3. **灵活调用**：在创建对话机器人时，用户可以将一个或多个知识库关联到机器人，配置召回分段的数量、匹配度阈值以及调用方式（自动或按需），使对话机器人能够准确调用相关知识。

通过这些功能，Coze 平台为 RAG 技术的实施提供了强有力的支持，使得非技术人员也能轻松创建和管理高效的知识库，提升对话机器人的回答效果。

在本篇内容中，我们将深入探讨如何优化知识库的 RAG 能力，提升回答效果。从预检索、检索到后检索的每一个环节，我们都会介绍具体的优化方法和实践建议，帮助您充分利用 Coze 平台的强大功能，打造出高效、智能的对话机器人。

## 了解 RAG 工作流程

要理解如何优化知识库的 RAG 能力，我们首先需要了解 RAG 的工作流程。**RAG 的核心流程可以分为三个主要步骤：预检索（Pre-Retrieval）、检索（Retrieval）和后检索（Post-Retrieval）**。我们将详细解释每个步骤的作用和挑战，并通过一些生活中的例子帮助您更好地理解。

### 预检索（Pre-Retrieval）

预检索是指在系统实际进行检索操作之前所做的准备工作。具体来说，就是将新的数据准备好并进行处理，使其能够被系统高效地利用。这包括数据的分段、向量化以及创建索引等步骤。

想象一下，你正在整理一本百科全书。为了方便查找，你先将这本书的内容分成若干小章节，每个章节都标上标签（比如“动物”、“植物”）。然后，你制作了一份详细的目录，列出了每个章节的起始页码。这就是预检索的过程：对数据进行分段和标记，使后续的查找变得更加方便。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/76c9ed55c4194d26b27bb5ea5674aab1~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=1024\&h=1024\&s=1407752\&e=png\&b=fbf9ec)

**具体步骤：**

1. **数据分段**：将长文本或大文档分成更小的片段。这类似于把一本大书分成很多小章节。
2. **向量化**：将每个片段转换成数学表示形式，即向量。向量可以理解为一串数字，用来表示片段的特征。
3. **创建索引**：建立索引，使系统能够快速找到与查询相关的片段。

### 检索（Retrieval）

检索是 RAG 工作流程的核心部分。在这个步骤中，系统会根据用户的查询，在知识库中寻找最相关的信息片段。

假设你想知道狮子的生活习性。你会打开那本整理好的百科全书，根据目录找到“动物”章节，然后快速翻到狮子的相关内容。这就是检索的过程：根据查询找到相关的信息。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/344df461e4cd45cd92aae7b9178cbe32~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=1024\&h=1024\&s=1142774\&e=png\&b=f8f0dc)

**具体步骤：**

1. **查询向量化**：将用户的查询转换为向量表示。
2. **相似度计算**：将查询向量与知识库中每个片段的向量进行比较，计算它们之间的相似度。相似度越高，说明内容越相关。
3. **检索相关片段**：根据相似度排序，从知识库中提取最相关的几个片段。

### 后检索（Post-Retrieval）

后检索是指在找到相关信息片段后，将这些信息整合到生成模型中，最终生成回答的过程。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/39d507303fb84765add3453ff575e603~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=1174&h=588&s=155896&e=png&b=fefefe)

当你找到了百科全书中关于狮子的所有相关章节后，你会把这些内容进行整理和总结，然后告诉别人关于狮子的详细信息。这就是后检索的过程：整合信息并生成最终的回答。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fd4056d029d342ad8c86cae77a30e6e7~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=1024\&h=1024\&s=942961\&e=png\&b=f3e7dc)

**具体步骤：**

1. **整合信息**：将检索到的相关片段整合到用户的查询中，形成一个完整的上下文。
2. **生成回答**：使用生成模型，根据整合后的上下文生成自然、流畅的回答。

通过以上步骤，RAG 技术能够从海量数据中快速找到相关信息，并生成高质量的回答。然而，每个步骤中都有可能遇到挑战，比如数据质量、检索效率以及生成的准确性等。理解这些挑战并加以优化，是提升 RAG 系统性能的关键。

在目前 Coze 平台上，用户关于知识库可优化的功能还不多，主要还是建立在**预检索优化**这个步骤上。所以在接下来的部分，我们将深入探讨一下如何优化这个步骤，帮助您打造更高效的知识库和 RAG 系统。

## 预检索优化

预检索是整个 RAG 流程的基础，优化预检索可以显著提升系统的整体性能。我们将从数据质量、切分优化和非结构化数据转换几个方面来探讨具体的优化方法。所以无论你是否使用 Coze 或者类似的平台去使用知识库，一开始的最佳实践都是需要将你的知识内容进行预检索优化的。

### 配置合适的自动调用策略

在添加知识库到指定 Bot 的时候，你会发现知识库区域上有个`自动调用`的按钮，其实这个按钮就是用来调节知识库的搜索策略、最大召回数量和最小匹配度，甚至是自定义回复和显示来源等。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/425da367239e49c4ac2841e054c20a03~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.png#?w=1986&h=1080&s=200990&e=png&a=1&b=f6f6f9)

这里我一个个选项来细说一下，首先我们先来说说 “**搜索策略**”，以下是官方的解释：

> 从知识库中获取知识的检索方式，不同的检索策略可以更有效地找到正确的信息，提高其生成的答案的准确性和可用性。

其中有三种具体的搜索策略：

* **语义搜索**：基于向量的文本相关性查询，推荐在需要理解语义关联度和跨语言查询的场景使用。
* **全文搜索**：依赖于关键词的全文搜索，推荐在搜索具有特定名称、缩写词、短语或 ID 的场景使用。
* **混合搜索**：结合全文检索与语义检索的优势，并对结果进行综合排序。

这里我举个比较典型的例子—— `图书管理员` ——来分别说说这三种搜索方式的区别吧。

**语义搜索**。当你想找一本关于"家庭教育"的书时，即使你没有提到书名，这位图书管理员也能根据你的需求，推荐给你一些相关的好书，比如《如何说孩子才会听》《爱的五种语言》等。他不仅理解你的话里有 "教育"、"家庭" 的意思，还能把中英文书目关联起来。这就是**语义搜索的特点：理解词语背后的含义，找出相关联的内容**。

**全文搜索**。全文搜索则像是书籍目录中的索引。当你知道要找的书名是《时间简史》时，你会直接翻到索引中的"S"或"T"部分，快速找到这本书的页码。**这个过程关注的是关键词的精准匹配。电脑里的文件搜索、论文引用查询，都离不开这种基于关键词的全文搜索方式**。

**混合搜索**。混合搜索就是把语义搜索和全文搜索这两位管理员的能力都利用起来。当你搜索 "霍金 大爆炸理论" 时，系统既能找到《时间简史》这本书，因为作者是"霍金"，也能找到一些讨论宇宙起源的科普读物，因为它们与"大爆炸理论"的主题相关。最后，系统会综合两种搜索结果的相关性，把最匹配的内容排在前面。这样你就可以兼顾搜索的精准度和广度了。

好了，回到这里的案例，我刚刚上传的是一个信息表格，里面存的都是一些每个特定车型的基本信息，很明显，我们需要的是可以通过关键词精准匹配到相关车型信息的功能，所以这里我们选择了**全文搜索**。

接下来我们解释一下 —— **最大召回数量**，官方的解释如下：

> 从知识库中返回给大模型的最大段落数，数值越大返回的内容越多

顾名思义，就是 AI Bot 最多返回给大模型的知识库内容的数量，数值越大，AI Bot 就越有可能返回越多的知识库内容给用户，当然也有可能是通过更多相关内容经过大模型的总结能力，输出更加精准的答案。

要注意的是，不是越多就越好的。这里返回的知识库内容，其实每次提问时也会隐性添加到提问的上下文中，大模型的一次会话中其短期记忆能力是有限的，如果每次都携带大量的上下文信息会容易让大模型对于历史上下文失忆，导致其无法准确理解当前的提问。

这里我还想提一句，你记得我们是可以设置大模型的设置`携带上下文轮数`的，其实我一直觉得这是一个伪设置。

因为一次会话上下文的最大值其实是取决于大模型本身的能力，你们看到的大模型后面加上的`8K`、`32K`，其实就是大模型一次会话最大的数据记忆量。

意味着**假设你设置了最大的上下文轮数以及知识库的最大召回数量，如果你的大模型本身的记忆能力不够，那么即使你设置的最大`携带上下文轮数`也可能无法达到**。

所以根据我们的需求，我们这个知识库的数据，其实只要匹配到几条信息就够了，毕竟除了给用户查询特定车型的在售信息，我也可以给用户根据其他数据，比如“年份”来推荐一些相关的车型。**这里设置默认为 3 条就够了**。

继续解释一下 —— **最小匹配度**，官方的解释如下：

> 根据设置的匹配度选取段落返回给大模型，低于设定匹配度的内容不会被召回

简单来说，就是 AI Bot 对于知识库中每条内容的匹配度，只有超过了这个设定值，才会被大模型返回给用户。比如默认的 0.5，表示 AI Bot 认为匹配度低于 50% 的内容，就不会被返回给用户，以此类推。

除此以外，我们还可以设置 —— **无召回回复**，这个选项其实是一个很好的功能，可以让你在知识库内容匹配不到的情况下，给用户一个默认的回复，比如 “抱歉，我暂时无法找到相关信息，您可以尝试换个关键词再试一下。”

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8b311032ca254918b11a8c718c92c7e1~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.png#?w=1350&h=718&s=139415&e=png&a=1&b=fefefe)

### 提高数据质量

数据质量对 RAG 系统的性能有着直接影响。如果输入的数据质量不好，那么输出的结果也会相应地受到影响，就像“你丢垃圾进来，产出的也只会是垃圾。” 因此，确保数据的高质量是优化预检索的第一步。

那应该怎么做呢？

首先可以考虑**数据清洗**。数据清洗是指去除数据中的无关信息和噪音。例如，删除特殊字符、多余的空格、HTML 标签等。就像整理房间一样，我们需要把不需要的东西清理掉，让有用的信息更显眼。

**具体操作：**

1. **去除无关文本**：删除文档中无关的部分，比如广告、版权声明等。
2. **纠正错误**：检查并修正拼写错误和语法错误。
3. **替换代词**：将代词（如“他”、“她”、“它”）替换为具体的人名或名词，这样在检索时更具语义意义。

在数据清洗之后，我们还可以给数据**添加一些元数据（Metadata）**，例如日期、类别、章节等。这些元数据可以帮助系统更好地组织和检索信息。

**具体操作：**

1. **添加时间**：在每个文档或相应文档的片段添加日期信息，方便可以实现基于语料时效性的检索，以保证数据的实时性。
2. **添加标签**：给每个文档片段添加描述性标签，比如“产品介绍”、“使用说明”等。
3. **分类标记**：标记文档的类别和章节，方便后续的精确检索。

### 切分优化

数据切分是指将长文本或大文档分成更小的片段。合适的切分大小和方式可以显著影响检索的效果。切分太细会导致信息碎片化，而切分太粗则可能包含过多无关信息。

切分大小需要根据具体应用场景进行调整。例如，在处理技术文档时，可以按照章节或段落进行切分；而在处理客户评论时，可以按照句子或短语进行切分。

**具体操作：**

1. **小切分大小**：对于需要精细检索的场景（如代码片段、客户评论），可以选择较小的切分大小，即类似每个代码块实现或者每个用户评论就切为一个片段。
2. **大切分大小**：对于需要上下文完整性的场景（如故事或案例），可以选择较大的切分大小，比如在 Coze 平台上，你上传的文档是 markdown 格式的，你可以基于 markdown 语法的标题 1 或 2 来切分片段，对应其文章每一个章节。而上传的是一些 Word 或者 PDF 文档，可能需要你人工进行切分。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2fba3df06fa24db4a35c6b2ba72d9e07~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.png#?w=2406&h=2108&s=932100&e=png&a=1&b=f2f2f5)

所以，Coze 平台的知识库基于两大文件格式类型 —— 文本和表格的优势就出来了。

当你的文档是表格类型的，表格天生的结构化特性就已经帮你实现了索引片段的切分，很适合直接作为`小切分大小`的实现，如下图：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0f63879c481b4ef9b6f35d0fdbff8aaa~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.png#?w=2386&h=1840&s=297949&e=png&a=1&b=f6f6f9)

而文本类型的文档，在自己对文档内容结构熟悉的情况下，我更推荐你去使用 Coze 知识库的`自定义分段设置`，甚至是`自定义的分段标识符`来更好地切分文档，如下图：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d8227c1c23074bc58388e3216f819f51~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.png#?w=2338&h=1532&s=191227&e=png&a=1&b=f4f4fb)

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/acc9033be6564b9c9b41edbe98de9dd1~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.png#?w=2360&h=1668&s=234086&e=png&a=1&b=f6f6fa)

### 非结构化数据转换

有时，我们需要处理非常杂乱且难以结构化的大量数据。手动整理这些数据不仅耗时费力，而且效果可能不佳。在这种情况下，我们可以利用大模型的能力或相关工具，将非结构化数据转换为结构化的问答对。具体实现的方式其实很多，这里我就拿一个大家都可以使用到的工具 Kimi Chat 大模型举例。

具体实现的方式其实很多，这里我就拿一个大家都可以使用到的工具 `Kimi Chat` 大模型举例。

例如，您可以使用 Kimi Chat 大模型上传一个非结构化的文档，然后向大模型提问：“帮我基于文章内容生成 100 个对应的知识问答对，要求逻辑正确，符合内容概念，输出 CSV 格式内容。” 这样，大模型就会自动生成一个包含问答对的 CSV 表格，方便您直接上传到知识库中。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/33bd32f7a34940d0ba8eb91f125e23f8~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=1664\&h=5254\&s=2949925\&e=png\&a=1\&b=292c33)

**具体操作：**

1. **上传文档**：将非结构化文档上传到 Kimi Chat 大模型。
2. **生成问答对**：向大模型提问，要求其生成符合内容的知识问答对。
3. **导出 CSV**：将生成的问答对导出为 CSV 格式，方便后续复制下来保存为一个 CSV 文件直接上传到知识库。

如果文档内容比较繁多复杂，可以与大模型多轮对话来生成多几次不同的问答对，以实现覆盖面更全的语料录入。通过这种方法，可以将杂乱的数据快速转化为结构化的知识问答对，大大简化数据整理的工作。这不仅提高了数据的利用效率，还能确保知识库中的信息更加规范和有序。

## 总结

本文主要探讨了如何优化知识库的检索增强生成（RAG）能力，以提升对话机器人的回答效果。文章首先介绍了 RAG 技术的概念和重要性，并指出 Coze 平台提供的知识库功能与 RAG 技术完美契合。

其中还详细解释了 RAG 的工作流程，包括预检索、检索和后检索三个主要步骤，其中重点讨论了预检索优化，因为这是目前 Coze 平台上用户可以优化的主要环节。

预检索优化的具体方法包括：

1. 提高数据质量

   * 数据清洗：去除无关信息和噪音；
   * 添加元数据：添加时间、标签、分类等信息。

2. 切分优化

   * 选择合适的切分大小：根据应用场景调整切分粒度；
   * 利用 Coze 平台的优势：表格类型文档天然适合小切分，文本类型文档可使用自定义分段设置。

3. 非结构化数据转换

   * 使用 Kimi Chat 等大模型工具，将非结构化文档转换为结构化的问答对；
   * 通过多轮对话，生成覆盖面更全的语料，并上传到知识库。

总的来说，本文提供了一系列实用的优化方法，帮助用户充分利用 Coze 平台的强大功能，打造高效、智能的对话机器人。不过，RAG 技术的应用还有很大的探索空间。通过不断优化每个环节，我们可以进一步提升知识库的利用效率和回答质量。这需要技术人员和业务人员的密切合作，以及持续的实践和创新。

## 参考资料

* [Advance RAG- Improve RAG performance](https://luv-bansal.medium.com/advance-rag-improve-rag-performance-208ffad5bb6a "https://luv-bansal.medium.com/advance-rag-improve-rag-performance-208ffad5bb6a")